{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# LightFM Demo v4 â€” Robust mapping (auto categories + period normalization)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# !pip install lightfm  # uncomment if needed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np, pandas as pd, re\nfrom pathlib import Path\nfrom lightfm import LightFM\nfrom lightfm.data import Dataset\nfrom lightfm.evaluation import auc_score\n\nDATA = Path('data')\ninter = pd.read_csv(DATA/'interactions_lightfm.csv')\nusers = pd.read_csv(DATA/'user_features.csv')\nitems = pd.read_csv(DATA/'item_features.csv')\nseason = pd.read_csv(DATA/'seasonality_features.csv')\n\nFULL_PERIODS = [f'month-{i}' for i in range(12,0,-1)]\n\ndef norm_period(v: str) -> str:\n    s = str(v).strip().lower().replace('_','-')\n    m = re.search(r'(?:month[- ]?)(\\d+)$', s)\n    if m:\n        k = max(1, min(12, int(m.group(1))))\n        return f'month-{k}'\n    return s\n\n# Normalize IDs\ninter['customer_id'] = inter['customer_id'].astype(str).str.strip()\nusers['customer_id']  = users['customer_id'].astype(str).str.strip()\n\n# Normalize period forms\ninter['period'] = inter['period'].map(norm_period)\nseason['period'] = season['period'].map(norm_period)\n\n# Complete season months\nfull = pd.DataFrame({'period': FULL_PERIODS})\nseason = full.merge(season, on='period', how='left')\nfor col in ['top_merchant','avg_ticket_size_top_merchant','promo_intensity','months_to_eid','months_to_newyear']:\n    if col in season.columns:\n        season[col] = season[col].ffill().bfill()\n\n# Auto categories from data\ncats_inter = inter['merchant_category'].dropna().astype(str).str.strip().unique().tolist()\ncats_items = items['merchant_category'].dropna().astype(str).str.strip().unique().tolist()\nCATEGORIES = sorted(set(cats_inter) | set(cats_items))\nPERIODS = FULL_PERIODS\n\n# Contextualized items\ninter['item_ctx'] = inter['merchant_category'].astype(str).str.strip() + '__' + inter['period']\n\n# Build full mapping universes\nall_user_ids = sorted(pd.unique(pd.concat([users['customer_id'], inter['customer_id']])))\nall_item_ids = [f\"{c}__{p}\" for c in CATEGORIES for p in PERIODS]\n\ndataset = Dataset()\ndataset.fit(users=all_user_ids, items=all_item_ids)\n\n# User features\nusers_feat = users.copy()\nif 'casa_log' not in users_feat.columns and 'casa_balance' in users_feat.columns:\n    users_feat['casa_log'] = np.log1p(users_feat['casa_balance'])\nusers_feat['casa_bin'] = pd.qcut(users_feat['casa_log'], q=5, duplicates='drop').astype(str)\nuser_features_tokens = [(r['customer_id'], [f\"age_band:{r.get('age_band','NA')}\", f\"years_band:{r.get('years_band','NA')}\", f\"casa_bin:{r['casa_bin']}\"]) for _, r in users_feat.iterrows()]\n\n# Item features\nprice_map = dict(zip(items['merchant_category'].astype(str), items.get('price_band','Medium').astype(str))) if 'price_band' in items.columns else {}\navg_ticket = dict(zip(items['merchant_category'].astype(str), items.get('avg_ticket_idr', 100000))) if 'avg_ticket_idr' in items.columns else {}\nseason = season.set_index('period')\n\ndef season_tokens(period):\n    row = season.loc[period]\n    feats = [f\"period:{period}\"]\n    if 'top_merchant' in row: feats.append(f\"top_merchant:{row['top_merchant']}\")\n    if 'months_to_eid' in row: feats.append(f\"eid_bucket:{int(min(3, max(1, 1 + (12 - int(row['months_to_eid']))//4 )))}\")\n    if 'months_to_newyear' in row: feats.append(f\"ny_bucket:{int(min(3, max(1, 1 + (12 - int(row['months_to_newyear']))//4 )))}\")\n    return feats\n\nitem_features_tokens = []\nfor c in CATEGORIES:\n    for p in PERIODS:\n        feats = [f'cat:{c}', f'price:{price_map.get(c, \"Medium\")}', f'avg_ticket_bin:{int(np.log10(max(1, int(avg_ticket.get(c, 100000)))))}']\n        feats += season_tokens(p)\n        item_features_tokens.append((f\"{c}__{p}\", feats))\n\nall_user_feats = sorted({f for _, fs in user_features_tokens for f in fs})\nall_item_feats = sorted({f for _, fs in item_features_tokens for f in fs})\ndataset.fit_partial(user_features=all_user_feats, item_features=all_item_feats)\n\nu_features = dataset.build_user_features(user_features_tokens, normalize=False)\ni_features = dataset.build_item_features(item_features_tokens, normalize=False)\n\n# Split interactions\ntrain_df = inter[inter['period'] != 'month-1'].copy()\nvalid_df = inter[inter['period'] == 'month-1'].copy()\n\ntrain_tuples = list(zip(train_df['customer_id'], train_df['item_ctx'], train_df['weight_ui'].astype(float)))\nvalid_tuples = list(zip(valid_df['customer_id'], valid_df['item_ctx'], valid_df['weight_ui'].astype(float)))\n\n(interactions_train, _wt_train) = dataset.build_interactions(train_tuples)\n(interactions_valid, _wt_valid) = dataset.build_interactions(valid_tuples)\n\nmodel = LightFM(loss='warp', no_components=64, learning_rate=0.05, random_state=42)\nmodel.fit(interactions_train, user_features=u_features, item_features=i_features, epochs=20, num_threads=4)\n\nval_auc = auc_score(model, interactions_valid, user_features=u_features, item_features=i_features, num_threads=4).mean()\nprint('Validation AUC (month-1):', float(val_auc))\n\nuser_id_map, user_feature_map, item_id_map, item_feature_map = dataset.mapping()"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Inference with target month\nk = 5\ntarget_month = 2  # change to the month you want (1..12)\nCATEGORIES = sorted({ic.split('__',1)[0] for ic in item_id_map.keys()})\ncurrent_items = [f\"{c}__month-{target_month}\" for c in CATEGORIES if f\"{c}__month-{target_month}\" in item_id_map]\n\nimport numpy as np\n\ndef topk_for_user(uid):\n    if uid not in user_id_map: return []\n    uidx = user_id_map[uid]\n    idxs = np.array([item_id_map[i] for i in current_items], dtype=np.int32)\n    scores = model.predict(uidx, idxs, user_features=u_features, item_features=i_features)\n    order = np.argsort(-scores)[:k]\n    return [(current_items[i], float(scores[i])) for i in order]\n\nall_users = users['customer_id'].astype(str).tolist()\nrows = []\nfor uid in all_users:\n    for rank, (item_ctx, score) in enumerate(topk_for_user(uid), start=1):\n        cat, _p = item_ctx.split('__',1)\n        rows.append({'customer_id': uid, 'merchant_category': cat, 'period_scored': f'month-{target_month}', 'rank': rank, 'score': score})\n\nout_df = pd.DataFrame(rows)\nprint('TopK rows:', len(out_df))\nfrom pathlib import Path\nout_path = Path('data') / f'topk_month_{target_month}.csv'\nout_df.to_csv(out_path, index=False)\nprint('Saved:', str(out_path))\n\nout_df.head(20)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}